{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eefaa3-7723-47f7-9b09-2014a86aac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "data_ftse = pd.read_csv(\"ftse100_adjclose_2023.csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "# Print number of successful tickers\n",
    "print(f\" Plotting {data_ftse.shape[1]} tickers\")\n",
    "\n",
    "# Plot all tickers\n",
    "plt.figure(figsize=(15, 8))\n",
    "for ticker in data_ftse.columns:\n",
    "    plt.plot(data_ftse.index, data_ftse[ticker], linewidth=0.8, alpha=0.6, label=ticker)\n",
    "\n",
    "plt.title(\"FTSE 100 Tickers\", fontsize=18)\n",
    "plt.xlabel(\"Date\",fontsize=17)\n",
    "plt.legend(data_ftse.columns[:10], loc=\"upper left\", fontsize=14)\n",
    "plt.ylabel(\"Adjusted Close Price (GBP)\",fontsize=18)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72120a2b-6775-4ea0-9336-5fe7a4f16a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Remove rows with any missing values \n",
    "cleaned_data = data_ftse.dropna()\n",
    "\n",
    "# Plot the cleaned data \n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Plot the stocks\n",
    "cleaned_data[data_ftse.columns].plot(ax=plt.gca(), legend=True)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"FTSE 100 Tickers\",fontsize=18)\n",
    "plt.xlabel(\"Date\",fontsize=18)\n",
    "plt.ylabel(\"Adjusted Close Price (GBP)\",fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.legend(data_ftse.columns[:10], loc=\"upper left\", fontsize=17)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a679801e-6adc-49e5-ab48-f56e84d1a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleaned_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93e3d48-d9d9-4554-86cc-1ec21061d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function for calculate ADF test p-value\n",
    "def calculate_adf_pvalue(series):\n",
    "    try:\n",
    "        return adfuller(series.dropna())[1]\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "# normalization methods\n",
    "methods = {\n",
    "    'min_max': MinMaxScaler(),\n",
    "    'z_score': StandardScaler(),\n",
    "    'robust_scaling': RobustScaler(),\n",
    "    'percentage_returns': 'pct',\n",
    "    'log_returns': 'log'\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Apply each method\n",
    "for name, method in methods.items():\n",
    "    if method == 'pct':\n",
    "        transformed = cleaned_data.pct_change().dropna()\n",
    "    elif method == 'log':\n",
    "        transformed = np.log(cleaned_data / cleaned_data.shift(1)).dropna()\n",
    "    else:\n",
    "        transformed = pd.DataFrame(\n",
    "            method.fit_transform(cleaned_data),\n",
    "            columns=cleaned_data.columns,\n",
    "            index=cleaned_data.index\n",
    "        )\n",
    "\n",
    "    summary_calculations = {\n",
    "        'mean': transformed.mean().mean(),\n",
    "        'std': transformed.std().mean(),\n",
    "        'min': transformed.min().min(),\n",
    "        'max': transformed.max().max(),\n",
    "        'median': transformed.median().median(),\n",
    "        'skewness': transformed.skew().mean(),\n",
    "        'kurtosis': transformed.kurtosis().mean(),\n",
    "        'adf_pvalue': transformed.apply(calculate_adf_pvalue).mean()\n",
    "    }\n",
    "    results[name] = summary_calculations\n",
    "\n",
    "# Display the comparison table\n",
    "results_df = pd.DataFrame(results).T\n",
    "display(results_df)\n",
    "\n",
    "ranking = results_df[['adf_pvalue']].sort_values('adf_pvalue')\n",
    "print(ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f874c521-9907-4dc0-8356-8333a9896e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "# Calculate percentage returns\n",
    "percentage_data = cleaned_data.pct_change().dropna()\n",
    "\n",
    "# Normalize using z-score\n",
    "zscore_data = pd.DataFrame(StandardScaler().fit_transform(percentage_data),\n",
    "                            index=percentage_data.index,\n",
    "                            columns=percentage_data.columns)\n",
    "\n",
    "# Transpose for clustering\n",
    "percentage_data = percentage_data.T\n",
    "zscore_data = zscore_data.T\n",
    "\n",
    "# KMeans clustering (adjust k)\n",
    "k = 5\n",
    "kmeans_pct = KMeans(n_clusters=k, random_state=42).fit(percentage_data)\n",
    "kmeans_z = KMeans(n_clusters=k, random_state=42).fit(zscore_data)\n",
    "\n",
    "# Evaluate clustering with silhouette score\n",
    "silhouette_pct = silhouette_score(percentage_data, kmeans_pct.labels_)\n",
    "silhouette_z = silhouette_score(zscore_data, kmeans_z.labels_)\n",
    "\n",
    "print(f\"Silhouette Score (Percentage Returns): {silhouette_pct:.4f}\")\n",
    "print(f\"Silhouette Score (Z-Score Normalized): {silhouette_z:.4f}\")\n",
    "\n",
    "# Hierarchical clustering (ward)\n",
    "linkage_pct = linkage(percentage_data, method='ward')\n",
    "linkage_z = linkage(zscore_data, method='ward')\n",
    "\n",
    "# Plot the dendrograms \n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "dendrogram(linkage_pct, labels=percentage_data.index, leaf_rotation=90)\n",
    "plt.title(\"Hierarchical Clustering (Percentage Returns)\", fontsize=14)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "dendrogram(linkage_z, labels=zscore_data.index, leaf_rotation=90)\n",
    "plt.title(\"Hierarchical Clustering (Z-Score Normalized)\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35214de8-1fc3-4e36-ba63-f1f130371020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Calculate percentage returns\n",
    "percentage_returns = cleaned_data.pct_change().dropna()\n",
    "\n",
    "returns_melted = percentage_returns.melt(var_name=\"Stock\", value_name=\"Daily Return\")\n",
    "\n",
    "# Plot the boxplot\n",
    "plt.figure(figsize=(18, 8))\n",
    "sns.boxplot(data=returns_melted, x=\"Stock\", y=\"Daily Return\", showfliers=True, palette=\"cividis\" )\n",
    "plt.xticks(rotation=90, fontsize=12)\n",
    "plt.title(\"Boxplot of Percentage Returns Normalization for FTSE 100 Stocks\", fontsize=18)\n",
    "plt.ylabel(\"Daily Return\",fontsize=18)\n",
    "plt.xlabel(\"Stock\",fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36caef82-fbe9-4fe6-a532-7fa10c1b0c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate skewness for each stock \n",
    "skew_values = percentage_returns.skew().sort_values()\n",
    "\n",
    "# Plot skewness values as a bar chart\n",
    "plt.figure(figsize=(18, 9))\n",
    "sns.barplot(x=skew_values.index, y=skew_values.values, palette=\"magma\")\n",
    "\n",
    "# Plot the skewness\n",
    "plt.xticks(rotation=90, fontsize=12)\n",
    "plt.title(\"Skewness of Normalized Closing Prices for FTSE100 Stocks\",fontsize=20)\n",
    "plt.xlabel(\"Stock\",fontsize=20)\n",
    "plt.ylabel(\"Skewness\",fontsize=20)\n",
    "plt.axhline(0, color='black', linewidth=1.2, linestyle='--')  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddb1e4b-25e6-4f93-8187-3d796f7cbb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Transpose Data\n",
    "X = percentage_returns.T \n",
    "\n",
    "# Apply Elbow method\n",
    "inertia = []\n",
    "K = range(1, 11)\n",
    "\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K, inertia, marker='o')\n",
    "plt.title(\"Elbow Method For Optimal k\",fontsize=14)\n",
    "plt.xlabel(\"Number of Clusters (k)\",fontsize=14)\n",
    "plt.ylabel(\"Inertia\",fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.xticks(K)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cabff42-36da-4db3-8a78-78369408746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.manifold import TSNE\n",
    "import umap.umap_ as umap\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "\n",
    "# Transpose percentage returns \n",
    "returns_matrix = percentage_returns.T  \n",
    "\n",
    "# Perform clustering\n",
    "n_clusters = 5  # set based on Elbow method\n",
    "clustering_model = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "cluster_labels = clustering_model.fit_predict(returns_matrix)\n",
    "\n",
    "#  Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(returns_matrix)\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, learning_rate=200)\n",
    "tsne_result = tsne.fit_transform(returns_matrix)\n",
    "\n",
    "# Apply UMAP\n",
    "reducer = umap.UMAP(random_state=42)\n",
    "umap_result = reducer.fit_transform(returns_matrix)\n",
    "\n",
    "# Evaluate cluster quality\n",
    "sil_pca = silhouette_score(pca_result, cluster_labels)\n",
    "db_pca = davies_bouldin_score(pca_result, cluster_labels)\n",
    "\n",
    "sil_tsne = silhouette_score(tsne_result, cluster_labels)\n",
    "db_tsne = davies_bouldin_score(tsne_result, cluster_labels)\n",
    "\n",
    "sil_umap = silhouette_score(umap_result, cluster_labels)\n",
    "db_umap = davies_bouldin_score(umap_result, cluster_labels)\n",
    "\n",
    "# Print results\n",
    "print(\"Silhouette Scores:\")\n",
    "print(f\"PCA: {sil_pca:.3f} | t-SNE: {sil_tsne:.3f} | UMAP: {sil_umap:.3f}\")\n",
    "\n",
    "print(\"\\nDavies-Bouldin Index:\")\n",
    "print(f\"PCA: {db_pca:.3f} | t-SNE: {db_tsne:.3f} | UMAP: {db_umap:.3f}\")\n",
    "\n",
    "# plot all three dimentional reduction technique\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# PCA\n",
    "axs[0].scatter(pca_result[:, 0], pca_result[:, 1], c=cluster_labels, cmap='tab10', s=50)\n",
    "axs[0].set_title('PCA Clusters', fontsize=14)\n",
    "axs[0].set_xlabel('Principal Component 1', fontsize=12)\n",
    "axs[0].set_ylabel('Principal Component 2', fontsize=12)\n",
    "\n",
    "# t-SNE\n",
    "axs[1].scatter(tsne_result[:, 0], tsne_result[:, 1], c=cluster_labels, cmap='tab10', s=50)\n",
    "axs[1].set_title('t-SNE Clusters', fontsize=14)\n",
    "axs[1].set_xlabel('t-SNE Dimension 1',fontsize=12)\n",
    "axs[1].set_ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "\n",
    "# UMAP\n",
    "axs[2].scatter(umap_result[:, 0], umap_result[:, 1], c=cluster_labels, cmap='tab10', s=50)\n",
    "axs[2].set_title('UMAP Clusters', fontsize=14)\n",
    "axs[2].set_xlabel('UMAP Dimension 1', fontsize=12)\n",
    "axs[2].set_ylabel('UMAP Dimension 2', fontsize=12)\n",
    "\n",
    "plt.suptitle('Dimensionality Reduction Comparison: PCA vs t-SNE vs UMAP', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f24b82-0b4c-40a9-943b-962c7042bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the percentage returns\n",
    "stock_returns = percentage_returns.T\n",
    "\n",
    "# Apply k-Means Clustering\n",
    "kmeans_model = KMeans(n_clusters=5, random_state=2, n_init=100)\n",
    "cluster_labels = kmeans_model.fit_predict(stock_returns)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "reduced_data = pca.fit_transform(stock_returns)\n",
    "\n",
    "# Create a DataFrame for clustering\n",
    "pca_df = pd.DataFrame(reduced_data, columns=[\"PC1\", \"PC2\"])\n",
    "pca_df[\"Cluster\"] = cluster_labels\n",
    "pca_df[\"Ticker\"] = stock_returns.index\n",
    "\n",
    "np.random.seed(32)\n",
    "label_indices = np.random.choice(pca_df.index, size=10, replace=False)\n",
    "\n",
    "# Plot the clustered stocks in 2D \n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.scatterplot(data=pca_df, x=\"PC1\", y=\"PC2\", hue=\"Cluster\", palette=\"viridis\", s=120, alpha=0.8, ax=ax)\n",
    "for i in label_indices:\n",
    "    ax.text(pca_df.loc[i, \"PC1\"], pca_df.loc[i, \"PC2\"], pca_df.loc[i, \"Ticker\"], fontsize=10, alpha=0.95)\n",
    "\n",
    "ax.set_title(\"K-Means Clustering (PCA)\",fontsize=16)\n",
    "ax.set_xlabel(\"Principal Component 1\", fontsize=14)\n",
    "ax.set_ylabel(\"Principal Component 1\",fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d9c0ca-5073-40fa-8ab7-9e0faa66e193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the percentage returns\n",
    "stock_returns = percentage_returns.T\n",
    "\n",
    "# Apply Agglomerative (Hierarchical) Clustering\n",
    "hier_model = AgglomerativeClustering(n_clusters=5, linkage='ward')\n",
    "cluster_labels = hier_model.fit_predict(stock_returns)\n",
    "\n",
    "# Reduce dimensionality to 2D using PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced_data = pca.fit_transform(stock_returns)\n",
    "\n",
    "pca_df = pd.DataFrame(reduced_data, columns=[\"PC1\", \"PC2\"])\n",
    "pca_df[\"Cluster\"] = cluster_labels\n",
    "pca_df[\"Ticker\"] = stock_returns.index\n",
    "\n",
    "np.random.seed(32)\n",
    "label_indices = np.random.choice(pca_df.index, size=10, replace=False)\n",
    "\n",
    "# Create scatter plot of pca data\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.scatterplot(data=pca_df, x=\"PC1\", y=\"PC2\", hue=\"Cluster\", palette=\"viridis\", s=120, alpha=0.8, ax=ax)\n",
    "\n",
    "for i in label_indices:\n",
    "    ax.text(pca_df.loc[i, \"PC1\"], pca_df.loc[i, \"PC2\"], pca_df.loc[i, \"Ticker\"], fontsize=10, alpha=0.85)\n",
    "\n",
    "ax.set_title(\"Hierarchical Clustering (PCA)\",fontsize=16)\n",
    "ax.set_xlabel(\"Principal Component 1\",fontsize=14)\n",
    "ax.set_ylabel(\"Principal Component 2\",fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b28e564-96ee-4c35-b340-ee7948f53afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "stock_returns = percentage_returns.T\n",
    "\n",
    "# Apply Spectral Clustering\n",
    "spectral_model = SpectralClustering(n_clusters=5, affinity='nearest_neighbors', random_state=42)\n",
    "cluster_labels = spectral_model.fit_predict(stock_returns)\n",
    "\n",
    "# Reduce dimensionality to 2D using PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced_data = pca.fit_transform(stock_returns)\n",
    "\n",
    "pca_df = pd.DataFrame(reduced_data, columns=[\"PC1\", \"PC2\"])\n",
    "pca_df[\"Cluster\"] = cluster_labels\n",
    "pca_df[\"Ticker\"] = stock_returns.index\n",
    "\n",
    "# create label for stocks\n",
    "np.random.seed(32)\n",
    "label_indices = np.random.choice(pca_df.index, size=10, replace=False)\n",
    "\n",
    "# Create scatter plot of pca data\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.scatterplot(data=pca_df, x=\"PC1\", y=\"PC2\", hue=\"Cluster\", palette=\"viridis\", s=120, alpha=0.8, ax=ax)\n",
    "\n",
    "for i in label_indices:\n",
    "    ax.text(pca_df.loc[i, \"PC1\"], pca_df.loc[i, \"PC2\"], pca_df.loc[i, \"Ticker\"], fontsize=10, alpha=0.85)\n",
    "\n",
    "ax.set_title(\"Spectral Clustering (PCA)\",fontsize=16)\n",
    "ax.set_xlabel(\"Principal Component 1\",fontsize=14)\n",
    "ax.set_ylabel(\"Principal Component 2\",fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56904b65-9e41-4402-a248-4f855828c884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "stock_returns = percentage_returns.T\n",
    "\n",
    "# Apply Gaussian Mixture Clustering\n",
    "gmm_model = GaussianMixture(n_components=5, random_state=2)\n",
    "cluster_labels = gmm_model.fit_predict(stock_returns)\n",
    "\n",
    "# Reduce dimensionality to 2D using PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced_data = pca.fit_transform(stock_returns)\n",
    "\n",
    "pca_df = pd.DataFrame(reduced_data, columns=[\"PC1\", \"PC2\"])\n",
    "pca_df[\"Cluster\"] = cluster_labels\n",
    "pca_df[\"Ticker\"] = stock_returns.index\n",
    "\n",
    "# create label\n",
    "np.random.seed(32)\n",
    "label_indices = np.random.choice(pca_df.index, size=10, replace=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.scatterplot(data=pca_df, x=\"PC1\", y=\"PC2\", hue=\"Cluster\", palette=\"viridis\", s=120, alpha=0.8, ax=ax)\n",
    "\n",
    "for i in label_indices:\n",
    "    ax.text(pca_df.loc[i, \"PC1\"], pca_df.loc[i, \"PC2\"], pca_df.loc[i, \"Ticker\"], fontsize=10, alpha=0.85)\n",
    "\n",
    "ax.set_title(\"Gaussian Mixture Model Clustering (PCA)\",fontsize=16)\n",
    "ax.set_xlabel(\"Principal Component 1\",fontsize=14)\n",
    "ax.set_ylabel(\"Principal Component 2\",fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd1231-0c62-4dc4-a62c-54a905b66da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "# Use normalized data \n",
    "stock_returns = percentage_returns.T\n",
    "\n",
    "# Store clustering evaluation scores\n",
    "results = []\n",
    "\n",
    "# Define clustering models\n",
    "models = {\n",
    "    \"KMeans\": KMeans(n_clusters=5, random_state=2, n_init=100),\n",
    "    \"Hierarchical\": AgglomerativeClustering(n_clusters=5, linkage='ward'),\n",
    "    \"Spectral\": SpectralClustering(n_clusters=5, affinity='nearest_neighbors', random_state=42),\n",
    "    \"GMM\": GaussianMixture(n_components=5, random_state=2)\n",
    "}\n",
    "\n",
    "# Evaluate each model using silhouette and Davies-Bouldin \n",
    "for method, model in models.items():\n",
    "    labels = model.fit_predict(stock_returns)\n",
    "    silhouette = silhouette_score(stock_returns, labels)\n",
    "    db_index = davies_bouldin_score(stock_returns, labels)\n",
    "    results.append({\n",
    "        \"Clustering Method\": method,\n",
    "        \"Silhouette Score\": silhouette,\n",
    "        \"Davies-Bouldin Index\": db_index\n",
    "    })\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "score_df = pd.DataFrame(results)\n",
    "\n",
    "colors = {\n",
    "    'KMeans': '#3EBCD2',\n",
    "    'Hierarchical': '#006BA2',\n",
    "    'Spectral': '#69C9B9',\n",
    "    'GMM': '#005F52'\n",
    "}\n",
    "\n",
    "score_df['Color'] = score_df['Clustering Method'].map(colors)\n",
    "\n",
    "# Plot the bar graph \n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "# plot the Silhouette Score\n",
    "sns.barplot(data=score_df, y=\"Clustering Method\", x=\"Silhouette Score\", ax=axes[0], palette=score_df.set_index(\"Clustering Method\")[\"Color\"].to_dict())\n",
    "axes[0].set_title(\"Silhouette Score by Clustering Method\", fontsize=18)\n",
    "axes[0].set_xlabel(\"Silhouette Score\", fontsize=16)\n",
    "axes[0].set_ylabel(\"Clustering Method\", fontsize=16)\n",
    "axes[0].tick_params(axis='y', labelsize=16)\n",
    "for container in axes[0].containers:\n",
    "    axes[0].bar_label(container, fmt=\"%.3f\", fontsize=14)\n",
    "\n",
    "# Plot the Davies Bouldin\n",
    "sns.barplot(data=score_df, y=\"Clustering Method\", x=\"Davies-Bouldin Index\", ax=axes[1], palette=score_df.set_index(\"Clustering Method\")[\"Color\"].to_dict())\n",
    "axes[1].set_title(\"Davies–Bouldin Index by Clustering Method\", fontsize=18)\n",
    "axes[1].set_xlabel(\"Davies–Bouldin Index\", fontsize=18)\n",
    "axes[1].set_ylabel(\"\")\n",
    "axes[1].tick_params(axis='y', labelsize=16)\n",
    "for container in axes[1].containers:\n",
    "    axes[1].bar_label(container, fmt=\"%.3f\", fontsize=14)\n",
    "\n",
    "legend_patches = [mpatches.Patch(color=colors[m], label=m) for m in models.keys()]\n",
    "fig.legend(handles=legend_patches, loc='upper center', ncol=4)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.94])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313fbc75-d58c-4de7-b2aa-ae43463d4aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Plot Dendrogram for Hierarchical Clustering\n",
    "linked = linkage(stock_returns, method='ward')\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "dendrogram(linked, labels=stock_returns.index, leaf_rotation=90, leaf_font_size=10)\n",
    "plt.title(\"Dendrogram of Stock Returns (Hierarchical Clustering)\")\n",
    "plt.xlabel(\"Stocks\", fontsize=14)\n",
    "plt.ylabel(\"Distance\",fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot the Heatmap\n",
    "distances = pdist(stock_returns, metric='euclidean')\n",
    "dist_matrix = pd.DataFrame(squareform(distances), \n",
    "                           index=stock_returns.index, \n",
    "                           columns=stock_returns.index)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.heatmap(dist_matrix, cmap=\"YlGnBu\", square=True, linewidths=0.5)\n",
    "plt.title(\"Heatmap of Stock Return Distances (Euclidean)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0764ed-6c72-4bd0-87dc-77a931a76b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Use raw adjusted close prices of TSCO\n",
    "TSCO_prices = data_ftse[\"TSCO.L\"].dropna()  \n",
    "TSCO_prices.index = pd.to_datetime(TSCO_prices.index)\n",
    "\n",
    "# Define ARIMA model \n",
    "model_full = sm.tsa.ARIMA(TSCO_prices, order=(40, 1, 2))\n",
    "results_full = model_full.fit()\n",
    "fitted_prices = results_full.fittedvalues\n",
    "\n",
    "# Plot Fitted price of TSCO stock\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(TSCO_prices, label=\"Actual Prices\", color='red')\n",
    "plt.plot(fitted_prices, label=\"ARIMA Fitted Prices\", color='blue')\n",
    "plt.title(\"TSCO.L - ARIMA Fit on Raw Prices (2023)\", fontsize=16)\n",
    "plt.xlabel(\"Date\", fontsize=14)\n",
    "plt.ylabel(\"Adjusted Close Price\",fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Split the data into training and test sets (80/20)\n",
    "split_TSCO = int(len(TSCO_prices) * 0.8)\n",
    "train_TSCO = TSCO_prices.iloc[:split_TSCO]\n",
    "test_Data = TSCO_prices.iloc[split_TSCO:]\n",
    "\n",
    "# Fit ARIMA model on the training set of TSCO stock\n",
    "model_split = sm.tsa.ARIMA(train_TSCO, order=(40, 1, 2))\n",
    "results_split = model_split.fit()\n",
    "\n",
    "# Forecast TSCO stock\n",
    "forecast = results_split.get_forecast(steps=len(test))\n",
    "forecast_mean = forecast.predicted_mean\n",
    "conf_int = forecast.conf_int()\n",
    "\n",
    "forecast_mean.index = test_Data.index\n",
    "conf_int.index = test_Data.index\n",
    "\n",
    "# calculated Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE)\n",
    "mae = mean_absolute_error(test_Data, forecast_mean)\n",
    "rmse = np.sqrt(mean_squared_error(test_Data, forecast_mean))\n",
    "print(f\"MAE: {mae:.4f}, RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Plot Forecast vs Actual price Of TSCO\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(train_TSCO[-60:], label=\"Training Prices\", color='black')\n",
    "plt.plot(test_Data, label=\"Actual Prices\", color='red', linestyle='--')\n",
    "plt.plot(forecast_mean, label=\"Forecasted Prices\", color='blue')\n",
    "plt.fill_between(forecast_mean.index,\n",
    "                 conf_int.iloc[:, 0],\n",
    "                 conf_int.iloc[:, 1],\n",
    "                 color='blue', alpha=0.2, label=\"Confidence Interval\")\n",
    "plt.title(\"TSCO.L Forecast on Prices (80:20 Split)\", fontsize=16)\n",
    "plt.xlabel(\"Date\",fontsize=14)\n",
    "plt.ylabel(\"Adjusted Close Price\",fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd382a-34c0-4465-a59a-3ea998c9a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Use raw adjusted close prices of DOCS\n",
    "DOCS_prices = data_ftse[\"DOCS.L\"].dropna()  \n",
    "DOCS_prices.index = pd.to_datetime(DOCS_prices.index)\n",
    "\n",
    "# Define ARIMA model \n",
    "model_full = sm.tsa.ARIMA(DOCS_prices, order=(5, 1, 1))\n",
    "results_full = model_full.fit()\n",
    "fitted_prices = results_full.fittedvalues\n",
    "\n",
    "# Plot Actual vs Fitted price of DOCS stock\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(DOCS_prices, label=\"Actual Prices\", color='red')\n",
    "plt.plot(fitted_prices, label=\"ARIMA Fitted Prices\", color='blue')\n",
    "plt.title(\"DOCS.L - ARIMA Fit on Raw Prices (2023)\", fontsize=16)\n",
    "plt.xlabel(\"Date\", fontsize=14)\n",
    "plt.ylabel(\"Adjusted Close Price\",fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Split the data into training and test sets (80/20)\n",
    "split_DOCS = int(len(DOCS_prices) * 0.8)\n",
    "train_DOCS = DOCS_prices.iloc[:split_DOCS]\n",
    "test_Data = DOCS_prices.iloc[split_DOCS:]\n",
    "\n",
    "# Fit ARIMA model on the training set of DOCS stock\n",
    "model_split = sm.tsa.ARIMA(train_DOCS, order=(5, 1, 1))\n",
    "results_split = model_split.fit()\n",
    "# Forecast DOCS stock\n",
    "forecast = results_split.get_forecast(steps=len(test))\n",
    "forecast_mean = forecast.predicted_mean\n",
    "conf_int = forecast.conf_int()\n",
    "\n",
    "forecast_mean.index = test_Data.index\n",
    "conf_int.index = test_Data.index\n",
    "\n",
    "# calculated Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE)\n",
    "mae = mean_absolute_error(test_Data, forecast_mean)\n",
    "rmse = np.sqrt(mean_squared_error(test_Data, forecast_mean))\n",
    "print(f\"MAE: {mae:.4f}, RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Plot Forecast vs Actual price Of DOCS\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(train_DOCS[-60:], label=\"Training Prices\", color='black')\n",
    "plt.plot(test_Data, label=\"Actual Prices\", color='red', linestyle='--')\n",
    "plt.plot(forecast_mean, label=\"Forecasted Prices\", color='blue')\n",
    "plt.fill_between(forecast_mean.index,\n",
    "                 conf_int.iloc[:, 0],\n",
    "                 conf_int.iloc[:, 1],\n",
    "                 color='blue', alpha=0.2, label=\"Confidence Interval\")\n",
    "plt.title(\"DOCS.L Forecast on Prices (80:20 Split)\", fontsize=16)\n",
    "plt.xlabel(\"Date\",fontsize=14)\n",
    "plt.ylabel(\"Adjusted Close Price\",fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a249091-e86a-4a9f-b49f-d3928f644360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Use raw adjusted close prices of OCDO\n",
    "OCDO_prices = data_ftse[\"OCDO.L\"].dropna()  \n",
    "OCDO_prices.index = pd.to_datetime(OCDO_prices.index)\n",
    "\n",
    "# Define ARIMA model \n",
    "model_full = sm.tsa.ARIMA(OCDO_prices, order=(53, 1, 2))\n",
    "results_full = model_full.fit()\n",
    "fitted_prices = results_full.fittedvalues\n",
    "\n",
    "# Plot Actual vs Fitted price of OCDO stock\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(OCDO_prices, label=\"Actual Prices\", color='red')\n",
    "plt.plot(fitted_prices, label=\"ARIMA Fitted Prices\", color='blue')\n",
    "plt.title(\"OCDO.L - ARIMA Fit on Raw Prices (2023)\", fontsize=16)\n",
    "plt.xlabel(\"Date\", fontsize=14)\n",
    "plt.ylabel(\"Adjusted Close Price\",fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Split the data into training and test sets (80/20)\n",
    "split_OCDO = int(len(OCDO_prices) * 0.8)\n",
    "train_OCDO = OCDO_prices.iloc[:split_OCDO]\n",
    "test_Data = OCDO_prices.iloc[split_OCDO:]\n",
    "\n",
    "# Fit ARIMA model on the training set of OCDO stock\n",
    "model_split = sm.tsa.ARIMA(train_OCDO, order=(53, 1, 2))\n",
    "results_split = model_split.fit()\n",
    "\n",
    "# Forecast OCDO stock\n",
    "forecast = results_split.get_forecast(steps=len(test))\n",
    "forecast_mean = forecast.predicted_mean\n",
    "conf_int = forecast.conf_int()\n",
    "\n",
    "forecast_mean.index = test_Data.index\n",
    "conf_int.index = test_Data.index\n",
    "\n",
    "# calculated Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE)\n",
    "mae = mean_absolute_error(test_Data, forecast_mean)\n",
    "rmse = np.sqrt(mean_squared_error(test_Data, forecast_mean))\n",
    "print(f\"MAE: {mae:.4f}, RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Plot Forecast vs Actual price Of OCDO\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(train_OCDO[-60:], label=\"Training Prices\", color='black')\n",
    "plt.plot(test_Data, label=\"Actual Prices\", color='red', linestyle='--')\n",
    "plt.plot(forecast_mean, label=\"Forecasted Prices\", color='blue')\n",
    "plt.fill_between(forecast_mean.index,\n",
    "                 conf_int.iloc[:, 0],\n",
    "                 conf_int.iloc[:, 1],\n",
    "                 color='blue', alpha=0.2, label=\"Confidence Interval\")\n",
    "plt.title(\"OCDO.L Forecast on Prices (80:20 Split)\", fontsize=16)\n",
    "plt.xlabel(\"Date\",fontsize=14)\n",
    "plt.ylabel(\"Adjusted Close Price\",fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e59d48d-576b-4844-afce-ef819a740d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
